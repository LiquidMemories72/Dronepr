{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3fc0d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing samples: 363\n",
      "Initial label: up\n",
      "label = down\n",
      "saved: down  total = 364\n",
      "saved: down  total = 365\n",
      "saved: down  total = 366\n",
      "saved: down  total = 367\n",
      "saved: down  total = 368\n",
      "saved: down  total = 369\n",
      "saved: down  total = 370\n",
      "saved: down  total = 371\n",
      "saved: down  total = 372\n",
      "saved: down  total = 373\n",
      "saved: down  total = 374\n",
      "saved: down  total = 375\n",
      "saved: down  total = 376\n",
      "saved: down  total = 377\n",
      "saved: down  total = 378\n",
      "saved: down  total = 379\n",
      "saved: down  total = 380\n",
      "saved: down  total = 381\n",
      "saved: down  total = 382\n",
      "saved: down  total = 383\n",
      "saved: down  total = 384\n",
      "saved: down  total = 385\n",
      "saved: down  total = 386\n",
      "saved: down  total = 387\n",
      "saved: down  total = 388\n",
      "saved: down  total = 389\n",
      "saved: down  total = 390\n",
      "saved: down  total = 391\n",
      "saved: down  total = 392\n",
      "saved: down  total = 393\n",
      "saved: down  total = 394\n",
      "saved: down  total = 395\n",
      "saved: down  total = 396\n",
      "saved: down  total = 397\n",
      "saved: down  total = 398\n",
      "saved: down  total = 399\n",
      "saved: down  total = 400\n",
      "saved: down  total = 401\n",
      "saved: down  total = 402\n",
      "no hand detected\n",
      "saved: down  total = 403\n",
      "no hand detected\n",
      "label = left\n",
      "saved: left  total = 404\n",
      "saved: left  total = 405\n",
      "saved: left  total = 406\n",
      "saved: left  total = 407\n",
      "saved: left  total = 408\n",
      "saved: left  total = 409\n",
      "saved: left  total = 410\n",
      "saved: left  total = 411\n",
      "saved: left  total = 412\n",
      "saved: left  total = 413\n",
      "saved: left  total = 414\n",
      "saved: left  total = 415\n",
      "saved: left  total = 416\n",
      "saved: left  total = 417\n",
      "saved: left  total = 418\n",
      "saved: left  total = 419\n",
      "saved: left  total = 420\n",
      "saved: left  total = 421\n",
      "saved: left  total = 422\n",
      "saved: left  total = 423\n",
      "saved: left  total = 424\n",
      "saved: left  total = 425\n",
      "saved: left  total = 426\n",
      "saved: left  total = 427\n",
      "saved: left  total = 428\n",
      "saved: left  total = 429\n",
      "saved: left  total = 430\n",
      "saved: left  total = 431\n",
      "saved: left  total = 432\n",
      "saved: left  total = 433\n",
      "saved: left  total = 434\n",
      "saved: left  total = 435\n",
      "label = right\n",
      "saved: right  total = 436\n",
      "saved: right  total = 437\n",
      "saved: right  total = 438\n",
      "saved: right  total = 439\n",
      "saved: right  total = 440\n",
      "saved: right  total = 441\n",
      "saved: right  total = 442\n",
      "saved: right  total = 443\n",
      "saved: right  total = 444\n",
      "saved: right  total = 445\n",
      "saved: right  total = 446\n",
      "saved: right  total = 447\n",
      "saved: right  total = 448\n",
      "saved: right  total = 449\n",
      "saved: right  total = 450\n",
      "saved: right  total = 451\n",
      "saved: right  total = 452\n",
      "saved: right  total = 453\n",
      "saved: right  total = 454\n",
      "saved: right  total = 455\n",
      "saved: right  total = 456\n",
      "saved: right  total = 457\n",
      "saved: right  total = 458\n",
      "saved: right  total = 459\n",
      "saved: right  total = 460\n",
      "saved: right  total = 461\n",
      "saved: right  total = 462\n",
      "saved: right  total = 463\n",
      "saved: right  total = 464\n",
      "saved: right  total = 465\n",
      "saved: right  total = 466\n",
      "saved: right  total = 467\n",
      "saved: right  total = 468\n",
      "saved: right  total = 469\n",
      "saved: right  total = 470\n",
      "saved: right  total = 471\n",
      "saved: right  total = 472\n",
      "saved: right  total = 473\n",
      "saved: right  total = 474\n",
      "saved: right  total = 475\n",
      "saved: right  total = 476\n",
      "saved: right  total = 477\n",
      "saved: right  total = 478\n",
      "saved: right  total = 479\n",
      "saved: right  total = 480\n",
      "saved: right  total = 481\n",
      "saved: right  total = 482\n",
      "saved: right  total = 483\n",
      "saved: right  total = 484\n",
      "saved: right  total = 485\n",
      "saved: right  total = 486\n",
      "saved: right  total = 487\n",
      "label = takeoff\n",
      "saved: takeoff  total = 488\n",
      "saved: takeoff  total = 489\n",
      "saved: takeoff  total = 490\n",
      "saved: takeoff  total = 491\n",
      "saved: takeoff  total = 492\n",
      "saved: takeoff  total = 493\n",
      "saved: takeoff  total = 494\n",
      "saved: takeoff  total = 495\n",
      "saved: takeoff  total = 496\n",
      "saved: takeoff  total = 497\n",
      "saved: takeoff  total = 498\n",
      "saved: takeoff  total = 499\n",
      "saved: takeoff  total = 500\n",
      "saved: takeoff  total = 501\n",
      "saved: takeoff  total = 502\n",
      "saved: takeoff  total = 503\n",
      "saved: takeoff  total = 504\n",
      "saved: takeoff  total = 505\n",
      "saved: takeoff  total = 506\n",
      "saved: takeoff  total = 507\n",
      "saved: takeoff  total = 508\n",
      "saved: takeoff  total = 509\n",
      "saved: takeoff  total = 510\n",
      "saved: takeoff  total = 511\n",
      "saved: takeoff  total = 512\n",
      "saved: takeoff  total = 513\n",
      "saved: takeoff  total = 514\n",
      "saved: takeoff  total = 515\n",
      "saved: takeoff  total = 516\n",
      "saved: takeoff  total = 517\n",
      "saved: takeoff  total = 518\n",
      "saved: takeoff  total = 519\n",
      "saved: takeoff  total = 520\n",
      "saved: takeoff  total = 521\n",
      "saved: takeoff  total = 522\n",
      "label = land\n",
      "label = takeoff\n",
      "label = land\n",
      "saved: land  total = 523\n",
      "saved: land  total = 524\n",
      "saved: land  total = 525\n",
      "no hand detected\n",
      "no hand detected\n",
      "saved: land  total = 526\n",
      "saved: land  total = 527\n",
      "saved: land  total = 528\n",
      "saved: land  total = 529\n",
      "saved: land  total = 530\n",
      "saved: land  total = 531\n",
      "saved: land  total = 532\n",
      "saved: land  total = 533\n",
      "saved: land  total = 534\n",
      "saved: land  total = 535\n",
      "no hand detected\n",
      "saved: land  total = 536\n",
      "no hand detected\n",
      "saved: land  total = 537\n",
      "saved: land  total = 538\n",
      "saved: land  total = 539\n",
      "saved: land  total = 540\n",
      "saved: land  total = 541\n",
      "no hand detected\n",
      "saved: land  total = 542\n",
      "no hand detected\n",
      "no hand detected\n",
      "saved: land  total = 543\n",
      "saved: land  total = 544\n",
      "saved: land  total = 545\n",
      "no hand detected\n",
      "saved: land  total = 546\n",
      "saved: land  total = 547\n",
      "saved: land  total = 548\n",
      "saved: land  total = 549\n",
      "no hand detected\n",
      "no hand detected\n",
      "no hand detected\n",
      "no hand detected\n",
      "saved: land  total = 550\n",
      "saved: land  total = 551\n",
      "saved: land  total = 552\n",
      "no hand detected\n",
      "saved: land  total = 553\n",
      "no hand detected\n",
      "label = flip\n",
      "saved: flip  total = 554\n",
      "no hand detected\n",
      "saved: flip  total = 555\n",
      "saved: flip  total = 556\n",
      "no hand detected\n",
      "saved: flip  total = 557\n",
      "saved: flip  total = 558\n",
      "saved: flip  total = 559\n",
      "saved: flip  total = 560\n",
      "saved: flip  total = 561\n",
      "no hand detected\n",
      "no hand detected\n",
      "saved: flip  total = 562\n",
      "saved: flip  total = 563\n",
      "saved: flip  total = 564\n",
      "saved: flip  total = 565\n",
      "saved: flip  total = 566\n",
      "saved: flip  total = 567\n",
      "saved: flip  total = 568\n",
      "no hand detected\n",
      "saved: flip  total = 569\n",
      "saved: flip  total = 570\n",
      "saved: flip  total = 571\n",
      "saved: flip  total = 572\n",
      "no hand detected\n",
      "saved: flip  total = 573\n",
      "saved: flip  total = 574\n",
      "saved: flip  total = 575\n",
      "saved: flip  total = 576\n",
      "saved: flip  total = 577\n",
      "saved: flip  total = 578\n",
      "no hand detected\n",
      "saved: flip  total = 579\n",
      "saved: flip  total = 580\n",
      "no hand detected\n",
      "saved: flip  total = 581\n",
      "saved: flip  total = 582\n",
      "saved: flip  total = 583\n",
      "no hand detected\n",
      "saved: flip  total = 584\n",
      "saved: flip  total = 585\n",
      "saved: flip  total = 586\n",
      "saved: flip  total = 587\n",
      "no hand detected\n",
      "saved: flip  total = 588\n",
      "Saved\n",
      "X shape: (588, 63)\n",
      "y shape: (588,)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# ----------------------------\n",
    "# Load existing dataset (if any)\n",
    "# ----------------------------\n",
    "X_file = \"X_landmarks.npy\"\n",
    "y_file = \"y_labels.npy\"\n",
    "\n",
    "\n",
    "if os.path.exists(X_file) and os.path.exists(y_file):\n",
    "    X = np.load(X_file, allow_pickle=True).tolist()\n",
    "    y = np.load(y_file, allow_pickle=True).tolist()\n",
    "    print(\"Loaded existing samples:\", len(X))\n",
    "else:\n",
    "    X = []\n",
    "    y = []\n",
    "    print(\"Starting new dataset\")\n",
    "\n",
    "# ----------------------------\n",
    "# Label\n",
    "# ----------------------------\n",
    "current_label = \"up\"\n",
    "print(\"Initial label:\", current_label)\n",
    "\n",
    "# ----------------------------\n",
    "# MediaPipe Tasks setup\n",
    "# ----------------------------\n",
    "BaseOptions = python.BaseOptions\n",
    "HandLandmarker = vision.HandLandmarker\n",
    "HandLandmarkerOptions = vision.HandLandmarkerOptions\n",
    "VisionRunningMode = vision.RunningMode\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=\"hand_landmarker.task\"),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    num_hands=1\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "timestamp = 0\n",
    "\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mp_image = mp.Image(\n",
    "            image_format=mp.ImageFormat.SRGB,\n",
    "            data=rgb\n",
    "        )\n",
    "\n",
    "        # timestamp must be increasing (milliseconds)\n",
    "        timestamp += 33\n",
    "\n",
    "        result = landmarker.detect_for_video(mp_image, timestamp)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if result.hand_landmarks:\n",
    "            hand = result.hand_landmarks[0]\n",
    "\n",
    "            h, w, _ = frame.shape\n",
    "            for lm in hand:\n",
    "                cx = int(lm.x * w)\n",
    "                cy = int(lm.y * h)\n",
    "                cv2.circle(frame, (cx, cy), 4, (0, 255, 0), -1)\n",
    "\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"Label: {current_label}\",\n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"Hand capture (MediaPipe Tasks)\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # ----------------------------\n",
    "        # Change label\n",
    "        # ----------------------------\n",
    "        if key == ord('1'):\n",
    "            current_label = \"up\"\n",
    "            print(\"label = up\")\n",
    "\n",
    "        elif key == ord('2'):\n",
    "            current_label = \"down\"\n",
    "            print(\"label = down\")\n",
    "\n",
    "        elif key == ord('3'):\n",
    "            current_label = \"left\"\n",
    "            print(\"label = left\")\n",
    "\n",
    "        elif key == ord('4'):\n",
    "            current_label = \"right\"\n",
    "            print(\"label = right\")\n",
    "\n",
    "        elif key == ord('5'):\n",
    "            current_label = \"takeoff\"\n",
    "            print(\"label = takeoff\")\n",
    "\n",
    "        elif key == ord('6'):\n",
    "            current_label = \"land\"\n",
    "            print(\"label = land\")\n",
    "\n",
    "        elif key == ord('7'):\n",
    "            current_label = \"flip\"\n",
    "            print(\"label = flip\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # Save one sample\n",
    "        # ----------------------------\n",
    "        elif key == ord('s'):\n",
    "            if result.hand_landmarks:\n",
    "                hand = result.hand_landmarks[0]\n",
    "\n",
    "                vec = []\n",
    "                for lm in hand:\n",
    "                    vec.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "                X.append(vec)\n",
    "                y.append(current_label)\n",
    "\n",
    "                print(\"saved:\", current_label, \" total =\", len(X))\n",
    "            else:\n",
    "                print(\"no hand detected\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # Quit and save\n",
    "        # ----------------------------\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "np.save(X_file, np.array(X, dtype=object))\n",
    "np.save(y_file, np.array(y, dtype=object))\n",
    "\n",
    "print(\"Saved\")\n",
    "print(\"X shape:\", np.array(X).shape)\n",
    "print(\"y shape:\", np.array(y).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50dd41dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (588, 63)\n",
      "y shape: (588,)\n",
      "Classes: ['down' 'flip' 'land' 'left' 'right' 'takeoff' 'up']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m455\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,903</span> (66.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,903\u001b[0m (66.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,903</span> (66.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,903\u001b[0m (66.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2362 - loss: 1.8749 - val_accuracy: 0.3475 - val_loss: 1.7886\n",
      "Epoch 2/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3979 - loss: 1.7538 - val_accuracy: 0.5169 - val_loss: 1.6454\n",
      "Epoch 3/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4574 - loss: 1.6432 - val_accuracy: 0.5339 - val_loss: 1.4990\n",
      "Epoch 4/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5426 - loss: 1.5006 - val_accuracy: 0.6525 - val_loss: 1.3524\n",
      "Epoch 5/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6234 - loss: 1.3385 - val_accuracy: 0.6780 - val_loss: 1.1906\n",
      "Epoch 6/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6489 - loss: 1.1980 - val_accuracy: 0.7542 - val_loss: 1.0437\n",
      "Epoch 7/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7064 - loss: 1.0739 - val_accuracy: 0.8220 - val_loss: 0.9253\n",
      "Epoch 8/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7043 - loss: 0.9797 - val_accuracy: 0.7966 - val_loss: 0.8471\n",
      "Epoch 9/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7532 - loss: 0.9103 - val_accuracy: 0.8136 - val_loss: 0.7591\n",
      "Epoch 10/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7723 - loss: 0.7997 - val_accuracy: 0.8644 - val_loss: 0.6825\n",
      "Epoch 11/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7957 - loss: 0.7320 - val_accuracy: 0.8644 - val_loss: 0.6182\n",
      "Epoch 12/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8043 - loss: 0.6837 - val_accuracy: 0.8644 - val_loss: 0.5610\n",
      "Epoch 13/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8298 - loss: 0.6345 - val_accuracy: 0.9237 - val_loss: 0.5404\n",
      "Epoch 14/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8447 - loss: 0.5936 - val_accuracy: 0.9237 - val_loss: 0.4801\n",
      "Epoch 15/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8447 - loss: 0.5417 - val_accuracy: 0.9492 - val_loss: 0.4425\n",
      "Epoch 16/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8787 - loss: 0.5001 - val_accuracy: 0.9492 - val_loss: 0.4117\n",
      "Epoch 17/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8489 - loss: 0.5092 - val_accuracy: 0.8729 - val_loss: 0.4661\n",
      "Epoch 18/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8596 - loss: 0.4786 - val_accuracy: 0.9407 - val_loss: 0.3892\n",
      "Epoch 19/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8723 - loss: 0.4461 - val_accuracy: 0.9407 - val_loss: 0.3498\n",
      "Epoch 20/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8957 - loss: 0.3947 - val_accuracy: 0.9237 - val_loss: 0.3337\n",
      "Epoch 21/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8936 - loss: 0.3868 - val_accuracy: 0.9407 - val_loss: 0.3164\n",
      "Epoch 22/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9170 - loss: 0.3586 - val_accuracy: 0.9407 - val_loss: 0.3036\n",
      "Epoch 23/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8979 - loss: 0.3578 - val_accuracy: 0.9407 - val_loss: 0.3035\n",
      "Epoch 24/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9191 - loss: 0.3448 - val_accuracy: 0.9492 - val_loss: 0.2921\n",
      "Epoch 25/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9255 - loss: 0.3127 - val_accuracy: 0.9322 - val_loss: 0.2708\n",
      "Epoch 26/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8936 - loss: 0.3366 - val_accuracy: 0.9407 - val_loss: 0.2883\n",
      "Epoch 27/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9234 - loss: 0.2970 - val_accuracy: 0.9068 - val_loss: 0.2679\n",
      "Epoch 28/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9298 - loss: 0.2913 - val_accuracy: 0.9492 - val_loss: 0.2536\n",
      "Epoch 29/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9277 - loss: 0.2915 - val_accuracy: 0.9407 - val_loss: 0.2451\n",
      "Epoch 30/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9149 - loss: 0.2724 - val_accuracy: 0.9407 - val_loss: 0.2568\n",
      "Epoch 31/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9383 - loss: 0.2693 - val_accuracy: 0.9237 - val_loss: 0.2705\n",
      "Epoch 32/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9340 - loss: 0.2573 - val_accuracy: 0.9492 - val_loss: 0.2414\n",
      "Epoch 33/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9255 - loss: 0.2414 - val_accuracy: 0.9576 - val_loss: 0.2188\n",
      "Epoch 34/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9511 - loss: 0.2079 - val_accuracy: 0.9407 - val_loss: 0.2072\n",
      "Epoch 35/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9383 - loss: 0.2136 - val_accuracy: 0.9492 - val_loss: 0.2064\n",
      "Epoch 36/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9383 - loss: 0.2275 - val_accuracy: 0.9322 - val_loss: 0.2734\n",
      "Epoch 37/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9362 - loss: 0.2459 - val_accuracy: 0.9492 - val_loss: 0.2026\n",
      "Epoch 38/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9426 - loss: 0.2082 - val_accuracy: 0.9407 - val_loss: 0.1908\n",
      "Epoch 39/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9362 - loss: 0.2116 - val_accuracy: 0.9661 - val_loss: 0.1759\n",
      "Epoch 40/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9617 - loss: 0.1938 - val_accuracy: 0.9492 - val_loss: 0.1918\n",
      "Model saved as gesture_model.keras\n",
      "Labels saved as label_classes.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ---------------------------\n",
    "# Load data\n",
    "# ---------------------------\n",
    "X = np.load(\"X_landmarks.npy\", allow_pickle=True)\n",
    "y = np.load(\"y_labels.npy\", allow_pickle=True)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "X = X.astype(\"float32\")\n",
    "\n",
    "# ---------------------------\n",
    "# Encode labels\n",
    "# ---------------------------\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "print(\"Classes:\", le.classes_)\n",
    "\n",
    "# ---------------------------\n",
    "# Train / validation split\n",
    "# ---------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Simple MLP model\n",
    "# (NOT CNN – landmarks are vectors, not images)\n",
    "# ---------------------------\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(63,)),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(len(le.classes_), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ---------------------------\n",
    "# Train\n",
    "# ---------------------------\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=40,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Save model + label map\n",
    "# ---------------------------\n",
    "model.save(\"gesture_model.keras\")\n",
    "np.save(\"label_classes.npy\", le.classes_)\n",
    "\n",
    "print(\"Model saved as gesture_model.keras\")\n",
    "print(\"Labels saved as label_classes.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89db374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['down' 'flip' 'land' 'left' 'right' 'takeoff' 'up']\n",
      "Gesture: up conf: 0.98\n",
      "DRONE : UP\n",
      "Gesture: land conf: 0.79\n",
      "DRONE : LAND\n",
      "Gesture: down conf: 0.97\n",
      "DRONE : DOWN\n",
      "Gesture: up conf: 0.71\n",
      "DRONE : UP\n",
      "Gesture: land conf: 0.73\n",
      "DRONE : LAND\n",
      "Gesture: up conf: 0.78\n",
      "DRONE : UP\n",
      "Gesture: land conf: 0.8\n",
      "DRONE : LAND\n",
      "Gesture: right conf: 0.85\n",
      "DRONE : RIGHT\n",
      "Gesture: up conf: 0.99\n",
      "DRONE : UP\n",
      "Gesture: right conf: 0.74\n",
      "DRONE : RIGHT\n",
      "Gesture: left conf: 0.71\n",
      "DRONE : LEFT\n",
      "Gesture: right conf: 0.78\n",
      "DRONE : RIGHT\n",
      "Gesture: down conf: 0.71\n",
      "DRONE : DOWN\n",
      "Gesture: flip conf: 0.85\n",
      "DRONE : FLIP\n",
      "Gesture: land conf: 0.75\n",
      "DRONE : LAND\n",
      "Gesture: down conf: 0.71\n",
      "DRONE : DOWN\n",
      "Gesture: land conf: 0.71\n",
      "DRONE : LAND\n",
      "Gesture: right conf: 0.71\n",
      "DRONE : RIGHT\n",
      "Gesture: up conf: 0.78\n",
      "DRONE : UP\n",
      "Gesture: land conf: 0.72\n",
      "DRONE : LAND\n",
      "Gesture: flip conf: 0.7\n",
      "DRONE : FLIP\n",
      "Gesture: land conf: 0.78\n",
      "DRONE : LAND\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from tensorflow import keras\n",
    "\n",
    "# ----------------------------\n",
    "# Load trained model + labels\n",
    "# ----------------------------\n",
    "model = keras.models.load_model(\"gesture_model.keras\")\n",
    "classes = np.load(\"label_classes.npy\", allow_pickle=True)\n",
    "\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "# ----------------------------\n",
    "# Dummy drone functions\n",
    "# ----------------------------\n",
    "def drone_up():      print(\"DRONE : UP\")\n",
    "def drone_down():    print(\"DRONE : DOWN\")\n",
    "def drone_left():    print(\"DRONE : LEFT\")\n",
    "def drone_right():   print(\"DRONE : RIGHT\")\n",
    "def drone_takeoff(): print(\"DRONE : TAKEOFF\")\n",
    "def drone_land():    print(\"DRONE : LAND\")\n",
    "def drone_flip():    print(\"DRONE : FLIP\")\n",
    "\n",
    "ACTION_MAP = {\n",
    "    \"up\": drone_up,\n",
    "    \"down\": drone_down,\n",
    "    \"left\": drone_left,\n",
    "    \"right\": drone_right,\n",
    "    \"takeoff\": drone_takeoff,\n",
    "    \"land\": drone_land,\n",
    "    \"flip\": drone_flip\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# MediaPipe Tasks setup\n",
    "# ----------------------------\n",
    "BaseOptions = python.BaseOptions\n",
    "HandLandmarker = vision.HandLandmarker\n",
    "HandLandmarkerOptions = vision.HandLandmarkerOptions\n",
    "VisionRunningMode = vision.RunningMode\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=\"hand_landmarker.task\"),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    num_hands=1\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "timestamp = 0\n",
    "\n",
    "last_gesture = None\n",
    "\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mp_image = mp.Image(\n",
    "            image_format=mp.ImageFormat.SRGB,\n",
    "            data=rgb\n",
    "        )\n",
    "\n",
    "        timestamp += 33\n",
    "\n",
    "        result = landmarker.detect_for_video(mp_image, timestamp)\n",
    "\n",
    "        predicted = \"\"\n",
    "\n",
    "        if result.hand_landmarks:\n",
    "\n",
    "            hand = result.hand_landmarks[0]\n",
    "\n",
    "            # 63-D feature vector\n",
    "            vec = []\n",
    "            for lm in hand:\n",
    "                vec.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "            x = np.array(vec, dtype=np.float32).reshape(1, 63)\n",
    "\n",
    "            probs = model.predict(x, verbose=0)[0]\n",
    "            idx = np.argmax(probs)\n",
    "\n",
    "            predicted = classes[idx]\n",
    "            conf = probs[idx]\n",
    "\n",
    "            # simple confidence gate\n",
    "            if conf > 0.70:\n",
    "                if predicted != last_gesture:\n",
    "                    last_gesture = predicted\n",
    "                    print(\"Gesture:\", predicted, \"conf:\", round(float(conf), 2))\n",
    "\n",
    "                    if predicted in ACTION_MAP:\n",
    "                        ACTION_MAP[predicted]()\n",
    "\n",
    "            # draw landmarks\n",
    "            h, w, _ = frame.shape\n",
    "            for lm in hand:\n",
    "                cx = int(lm.x * w)\n",
    "                cy = int(lm.y * h)\n",
    "                cv2.circle(frame, (cx, cy), 4, (0,255,0), -1)\n",
    "\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"Gesture: {predicted}\",\n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0,255,0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"Live gesture control\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603c5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesture: up conf: 1.0\n",
      "DRONE : UP\n",
      "Gesture: left conf: 0.88\n",
      "DRONE : LEFT\n",
      "Gesture: down conf: 1.0\n",
      "DRONE : DOWN\n",
      "Gesture: left conf: 1.0\n",
      "DRONE : LEFT\n",
      "Gesture: right conf: 0.94\n",
      "DRONE : RIGHT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "import time\n",
    "\n",
    "HOLD_TIME = 0.4  # seconds (try 0.4–0.8)\n",
    "last_switch_time = 0.0\n",
    "\n",
    "smooth_pt = None\n",
    "SMOOTH_ALPHA = 0.2   # lower = smoother, higher = more reactive\n",
    "\n",
    "def init_path_plot():\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Simulated Drone Path (X–Z plane)\")\n",
    "    ax.set_xlabel(\"X (m)\")\n",
    "    ax.set_ylabel(\"Z (m)\")\n",
    "    ax.grid(True)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "drone_traj = []\n",
    "# -------------------------------------------------\n",
    "# Load trained gesture model\n",
    "# -------------------------------------------------\n",
    "\n",
    "model = keras.models.load_model(\"gesture_model.keras\")\n",
    "classes = np.load(\"label_classes.npy\", allow_pickle=True)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Dummy drone actions (gesture mode)\n",
    "# -------------------------------------------------\n",
    "\n",
    "def drone_up():      print(\"DRONE : UP\")\n",
    "def drone_down():    print(\"DRONE : DOWN\")\n",
    "def drone_left():    print(\"DRONE : LEFT\")\n",
    "def drone_right():   print(\"DRONE : RIGHT\")\n",
    "def drone_takeoff(): print(\"DRONE : TAKEOFF\")\n",
    "def drone_land():    print(\"DRONE : LAND\")\n",
    "def drone_flip():    print(\"DRONE : FLIP\")\n",
    "\n",
    "ACTION_MAP = {\n",
    "    \"up\": drone_up,\n",
    "    \"down\": drone_down,\n",
    "    \"left\": drone_left,\n",
    "    \"right\": drone_right,\n",
    "    \"takeoff\": drone_takeoff,\n",
    "    \"land\": drone_land,\n",
    "    \"flip\": drone_flip\n",
    "}\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# MediaPipe Tasks setup\n",
    "# -------------------------------------------------\n",
    "\n",
    "BaseOptions = python.BaseOptions\n",
    "HandLandmarker = vision.HandLandmarker\n",
    "HandLandmarkerOptions = vision.HandLandmarkerOptions\n",
    "VisionRunningMode = vision.RunningMode\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=\"hand_landmarker.task\"),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    num_hands=1\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# State machine\n",
    "# -------------------------------------------------\n",
    "\n",
    "MODE = \"IDLE\"     # IDLE | DRAW | EXECUTE \n",
    "\n",
    "draw_path = []\n",
    "last_draw_pt = None\n",
    "\n",
    "# simulated drone position\n",
    "# X – left/right\n",
    "# Y – fixed\n",
    "# Z – up/down\n",
    "drone_pos = np.array([0.0, 0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "EXEC_SCALE = 2.0        # meters per normalized finger motion\n",
    "EXEC_DT = 0.05         # seconds between steps\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------\n",
    "def draw_live_plot(traj_x, traj_z, size=400):\n",
    "    canvas = np.ones((size, size, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    if len(traj_x) < 2:\n",
    "        return canvas\n",
    "\n",
    "    xs = np.array(traj_x)\n",
    "    zs = np.array(traj_z)\n",
    "\n",
    "    # normalize to [0,1]\n",
    "    xs = (xs - xs.min()) / (xs.max() - xs.min() + 1e-6)\n",
    "    zs = (zs - zs.min()) / (zs.max() - zs.min() + 1e-6)\n",
    "\n",
    "    pts = []\n",
    "    for x, z in zip(xs, zs):\n",
    "        px = int(x * (size - 20)) + 10\n",
    "        py = int((1 - z) * (size - 20)) + 10\n",
    "        pts.append((px, py))\n",
    "\n",
    "    for i in range(1, len(pts)):\n",
    "        cv2.line(canvas, pts[i-1], pts[i], (255, 0, 0), 2)\n",
    "\n",
    "    return canvas\n",
    "\n",
    "def distance(p1, p2):\n",
    "    return np.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)\n",
    "\n",
    "\n",
    "def build_deltas_2d(path):\n",
    "   \n",
    "\n",
    "    pts = np.array(path, dtype=np.float32)\n",
    "\n",
    "    # center\n",
    "    pts = pts - pts.mean(axis=0)\n",
    "\n",
    "    # normalise scale independently per axis\n",
    "    std = pts.std(axis=0) + 1e-6\n",
    "    pts = pts / std\n",
    "\n",
    "    deltas = []\n",
    "    for i in range(len(pts) - 1):\n",
    "        dx = pts[i+1, 0] - pts[i, 0]\n",
    "        dy = pts[i+1, 1] - pts[i, 1]\n",
    "        deltas.append((dx, dy))\n",
    "\n",
    "    return deltas\n",
    "\n",
    "\n",
    "\n",
    "def execute_path_2d(deltas):\n",
    "    traj_x = [0.0]\n",
    "    traj_z = [0.0] \n",
    "\n",
    "    sim_x = 0.0\n",
    "    sim_z = 0.0\n",
    "\n",
    "    for dx, dy in deltas:\n",
    "\n",
    "        dX = dx\n",
    "        dZ = -dy\n",
    "\n",
    "        sim_x += EXEC_SCALE * dX\n",
    "        sim_z += EXEC_SCALE * dZ\n",
    "\n",
    "        traj_x.append(sim_x)\n",
    "        traj_z.append(sim_z)\n",
    "\n",
    "        drone_pos[0] += EXEC_SCALE * dX\n",
    "        drone_pos[2] += EXEC_SCALE * dZ\n",
    "\n",
    "        plot_img = draw_live_plot(traj_x, traj_z)\n",
    "\n",
    "        cv2.imshow(\"Drone path (live X–Z)\", plot_img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        time.sleep(EXEC_DT)\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Prediction smoothing\n",
    "# -------------------------------------------------\n",
    "\n",
    "pred_buffer = deque(maxlen=5)\n",
    "last_gesture = None\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Camera\n",
    "# -------------------------------------------------\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "timestamp = 0\n",
    "\n",
    "\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "\n",
    "    executing = False\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mp_image = mp.Image(\n",
    "            image_format=mp.ImageFormat.SRGB,\n",
    "            data=rgb\n",
    "        )\n",
    "\n",
    "        timestamp += 33\n",
    "\n",
    "        result = landmarker.detect_for_video(mp_image, timestamp)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Mode switching\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        if key == ord('d'):\n",
    "            if MODE != \"DRAW\":\n",
    "                MODE = \"DRAW\"\n",
    "                draw_path = []\n",
    "                last_draw_pt = None\n",
    "                print(\"MODE = DRAW\")\n",
    "            else:\n",
    "                MODE = \"IDLE\"\n",
    "                print(\"MODE = IDLE\")\n",
    "\n",
    "        if key == ord('e'):\n",
    "            if MODE == \"IDLE\" and len(draw_path) > 5:\n",
    "                MODE = \"EXECUTE\"\n",
    "                executing = False\n",
    "                print(\"MODE = EXECUTE\")\n",
    "\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # DRAW MODE\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        if MODE == \"DRAW\" and result.hand_landmarks:\n",
    "            hand = result.hand_landmarks[0]\n",
    "            tip = hand[8]\n",
    "\n",
    "            global smooth_pt\n",
    "\n",
    "            raw = np.array([tip.x, tip.y], dtype=np.float32)\n",
    "\n",
    "            if smooth_pt is None:\n",
    "                smooth_pt = raw\n",
    "            else:\n",
    "                smooth_pt = (1 - SMOOTH_ALPHA) * smooth_pt + SMOOTH_ALPHA * raw\n",
    "\n",
    "            curr = (float(smooth_pt[0]), float(smooth_pt[1]))\n",
    "\n",
    "            if last_draw_pt is None:\n",
    "                draw_path.append(curr)\n",
    "                last_draw_pt = curr\n",
    "            else:\n",
    "                if distance(curr, last_draw_pt) > 0.003:\n",
    "                    draw_path.append(curr)\n",
    "                    last_draw_pt = curr\n",
    "\n",
    "\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # EXECUTE MODE\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        if MODE == \"EXECUTE\" and not executing:\n",
    "\n",
    "            executing = True\n",
    "            print(\"Drawn points =\", len(draw_path))\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            xs = [p[0] for p in draw_path]\n",
    "            ys = [p[1] for p in draw_path]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.title(\"Raw finger path (camera space)\")\n",
    "            plt.plot(xs, ys)\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.axis(\"equal\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            deltas = build_deltas_2d(draw_path)\n",
    "\n",
    "            execute_path_2d(deltas)\n",
    "\n",
    "            MODE = \"IDLE\"\n",
    "            executing = False\n",
    "            last_gesture = None\n",
    "            pred_buffer.clear()\n",
    "\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # IDLE MODE  (gesture control)\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        predicted = \"\"\n",
    "\n",
    "        if MODE == \"IDLE\" and result.hand_landmarks:\n",
    "\n",
    "            hand = result.hand_landmarks[0]\n",
    "\n",
    "            vec = []\n",
    "            for lm in hand:\n",
    "                vec.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "            x = np.array(vec, dtype=np.float32).reshape(1, 63)\n",
    "\n",
    "            probs = model.predict(x, verbose=0)[0]\n",
    "            idx = np.argmax(probs)\n",
    "\n",
    "            pred_buffer.append(idx)\n",
    "            idx_s = max(set(pred_buffer), key=pred_buffer.count)\n",
    "\n",
    "            predicted = classes[idx_s]\n",
    "            conf = probs[idx_s]\n",
    "\n",
    "            if conf > 0.70:\n",
    "\n",
    "                now = time.time()\n",
    "\n",
    "                if predicted != last_gesture:\n",
    "\n",
    "                    # allow change only if enough time passed\n",
    "                    if now - last_switch_time < HOLD_TIME:\n",
    "                        predicted = last_gesture\n",
    "                    else:\n",
    "                        last_gesture = predicted\n",
    "                        last_switch_time = now\n",
    "\n",
    "                        if predicted in ACTION_MAP:\n",
    "                            ACTION_MAP[predicted]()\n",
    "\n",
    "\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Drawing landmarks (visual only)\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        if result.hand_landmarks:\n",
    "            hand = result.hand_landmarks[0]\n",
    "            for lm in hand:\n",
    "                cx = int(lm.x * w)\n",
    "                cy = int(lm.y * h)\n",
    "                cv2.circle(frame, (cx, cy), 4, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Draw the drawn finger path\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        if len(draw_path) > 1:\n",
    "            pts = []\n",
    "            for p in draw_path:\n",
    "                px = int(p[0] * w)\n",
    "                py = int(p[1] * h)\n",
    "                pts.append((px, py))\n",
    "\n",
    "            for i in range(1, len(pts)):\n",
    "                cv2.line(frame, pts[i-1], pts[i], (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # UI text\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"MODE: {MODE}\",\n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0, 255, 255),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"Drone XZ (m): {drone_pos[0]:.2f}, {drone_pos[2]:.2f}\",\n",
    "            (10, 65),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.8,\n",
    "            (255, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        if MODE == \"IDLE\":\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Gesture: {predicted}\",\n",
    "                (10, 100),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                (0, 255, 0),\n",
    "                2\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"Drone path control\", frame)\n",
    "\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3c784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65f132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
